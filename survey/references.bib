@article{watkins1992q,
  title     = {Q-learning},
  author    = {Watkins, Christopher JCH and Dayan, Peter},
  journal   = {Machine learning},
  volume    = {8},
  number    = {3},
  pages     = {279--292},
  year      = {1992},
  publisher = {Springer}
}

@article{silver2021reward,
  title     = {Reward is enough},
  author    = {Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S},
  journal   = {Artificial Intelligence},
  volume    = {299},
  pages     = {103535},
  year      = {2021},
  publisher = {Elsevier}
}

@article{mnih2013playing,
  title   = {Playing atari with deep reinforcement learning},
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal = {arXiv preprint arXiv:1312.5602},
  year    = {2013}
}

@article{russell2002artificial,
  title   = {Artificial intelligence: a modern approach},
  author  = {Russell, Stuart and Norvig, Peter},
  journal = {Artificial Intelligence},
  year    = {2002}
}

@misc{silver2015,
  author       = {David Silver},
  title        = {Lectures on Reinforcement Learning},
  howpublished = {https://www.davidsilver.uk/teaching/},
  year         = {2015}
}

@article{karpathy2016deep,
  title   = {Deep reinforcement learning: Pong from pixels},
  author  = {Karpathy, Andrej},
  journal = {url: http://karpathy. github. io/2016/05/31/rl},
  year    = {2016}
}

@phdthesis{sutton1984temporal,
  title  = {Temporal credit assignment in reinforcement learning},
  author = {Sutton, Richard Stuart},
  year   = {1984},
  school = {University of Massachusetts Amherst}
}

@article{parker2022automated,
  title   = {Automated Reinforcement Learning (AutoRL): A Survey and Open Problems},
  author  = {Parker-Holder, Jack and Rajan, Raghu and Song, Xingyou and Biedenkapp, Andr{\'e} and Miao, Yingjie and Eimer, Theresa and Zhang, Baohe and Nguyen, Vu and Calandra, Roberto and Faust, Aleksandra and others},
  journal = {arXiv preprint arXiv:2201.03916},
  year    = {2022}
}

@inproceedings{qiang2011reinforcement,
  title        = {Reinforcement learning model, algorithms and its application},
  author       = {Qiang, Wang and Zhongli, Zhan},
  booktitle    = {2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)},
  pages        = {1143--1146},
  year         = {2011},
  organization = {IEEE}
}

@inproceedings{learningagents,
  author  = {Wang, Rui and Wang, Xiangyu and Wang, Wei},
  year    = {2009},
  month   = {01},
  pages   = {221-226},
  title   = {Motivated Learning Agent Model for Distributed Collaborative Systems},
  journal = {Proceedings of the 2009 13th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2009},
  doi     = {10.1109/CSCWD.2009.4968062}
}

@inproceedings{melo2008analysis,
  title     = {An analysis of reinforcement learning with function approximation},
  author    = {Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle = {Proceedings of the 25th international conference on Machine learning},
  pages     = {664--671},
  year      = {2008}
}



@incollection{huys2014reward,
  title     = {Reward-based learning, model-based and model-free},
  author    = {Huys, Quentin JM and Cruickshank, Anthony and Seri{\`e}s, Peggy},
  booktitle = {Encyclopedia of Computational Neuroscience},
  pages     = {1--10},
  year      = {2014},
  publisher = {Springer New York}
}

@article{russell2021artificial,
  title   = {Artificial intelligence: a modern approach, global edition 4th},
  author  = {Russell, Stuart and Norvig, Peter},
  journal = {Foundations},
  volume  = {19},
  pages   = {23},
  year    = {2021}
}

@book{sutton2018reinforcement,
  title     = {Reinforcement learning: An introduction},
  author    = {Sutton, Richard S and Barto, Andrew G},
  year      = {2018},
  publisher = {MIT press}
}

@article{panait2005cooperative,
  title     = {Cooperative multi-agent learning: The state of the art},
  author    = {Panait, Liviu and Luke, Sean},
  journal   = {Autonomous agents and multi-agent systems},
  volume    = {11},
  number    = {3},
  pages     = {387--434},
  year      = {2005},
  publisher = {Springer}
}

@inproceedings{vikhar2016evolutionary,
  title        = {Evolutionary algorithms: A critical review and its future prospects},
  author       = {Vikhar, Pradnya A},
  booktitle    = {2016 International conference on global trends in signal processing, information computing and communication (ICGTSPICC)},
  pages        = {261--265},
  year         = {2016},
  organization = {IEEE}
}

@inproceedings{langdon2005evolutionary,
  title        = {Evolutionary solo pong players},
  author       = {Langdon, William B and Poll, R},
  booktitle    = {2005 IEEE Congress on Evolutionary Computation},
  volume       = {3},
  pages        = {2621--2628},
  year         = {2005},
  organization = {IEEE}
}

@article{mcbrien2020learning,
  title   = {LEARNING PONG},
  journal = {Nan},
  author  = {McBrien, Matthew and Melehan, Alexandra and Munns, Matthew},
  year    = {2020}
}

@article{stanley2019designing,
  title     = {Designing neural networks through neuroevolution},
  author    = {Stanley, Kenneth O and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
  journal   = {Nature Machine Intelligence},
  volume    = {1},
  number    = {1},
  pages     = {24--35},
  year      = {2019},
  publisher = {Nature Publishing Group}
}

@article{melo2001convergence,
  title   = {Convergence of Q-learning: A simple proof},
  author  = {Melo, Francisco S},
  journal = {Institute Of Systems and Robotics, Tech. Rep},
  pages   = {1--4},
  year    = {2001}
}

@article{arulkumaran2017deep,
  title     = {Deep reinforcement learning: A brief survey},
  author    = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal   = {IEEE Signal Processing Magazine},
  volume    = {34},
  number    = {6},
  pages     = {26--38},
  year      = {2017},
  publisher = {IEEE}
}

@inproceedings{makarov2017learning,
  title     = {Learning to Play Pong Video Game via Deep Reinforcement Learning.},
  author    = {Makarov, Ilya and Kashin, Andrej and Korinevskaya, Alisa},
  booktitle = {AIST (Supplement)},
  pages     = {236--241},
  year      = {2017}
}

@article{blundell2016model,
  title   = {Model-free episodic control},
  author  = {Blundell, Charles and Uria, Benigno and Pritzel, Alexander and Li, Yazhe and Ruderman, Avraham and Leibo, Joel Z and Rae, Jack and Wierstra, Daan and Hassabis, Demis},
  journal = {arXiv preprint arXiv:1606.04460},
  year    = {2016}
}

@inproceedings{diallo2017learning,
  title        = {Learning to coordinate with deep reinforcement learning in doubles pong game},
  author       = {Diallo, Elhadji Amadou Oury and Sugiyama, Ayumi and Sugawara, Toshiharu},
  booktitle    = {2017 16th IEEE international conference on machine learning and applications (ICMLA)},
  pages        = {14--19},
  year         = {2017},
  organization = {IEEE}
}

@article{tampuu2017multiagent,
  title     = {Multiagent cooperation and competition with deep reinforcement learning},
  author    = {Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan and Vicente, Raul},
  journal   = {PloS one},
  volume    = {12},
  number    = {4},
  pages     = {e0172395},
  year      = {2017},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@article{mnih2015human,
  title     = {Human-level control through deep reinforcement learning},
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal   = {nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@techreport{dahlstrom2002imitative,
  title       = {Imitative policies for reinforcement learning},
  author      = {Dahlstrom, Dana and Viewiora, E and Cottrell, G and Elkan, C},
  year        = {2002},
  institution = {Technical Report, Department of Computer Science and Engineering, University~â€¦}
}
